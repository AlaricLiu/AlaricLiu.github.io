<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>HDFS HA Deployment (With QJM) | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="运营管理平台HDFS高可用配置-实施版Overview目的以及方案目的为解决当前平台中NameNode为单点的问题. 方案如下: 

通过QJM在集群中实现两个NameNode, 一个为Active, 一个Standby.Standby为Active的热备份. 则Active节点产生故障, 可以手动故障切换Standby为Active. 
通过ZooKeeper实现自动的故障切换

系统逻辑结构">
<meta property="og:type" content="article">
<meta property="og:title" content="HDFS HA Deployment (With QJM)">
<meta property="og:url" content="http://yoursite.com/2016/04/13/HDFS高可用部署/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="运营管理平台HDFS高可用配置-实施版Overview目的以及方案目的为解决当前平台中NameNode为单点的问题. 方案如下: 

通过QJM在集群中实现两个NameNode, 一个为Active, 一个Standby.Standby为Active的热备份. 则Active节点产生故障, 可以手动故障切换Standby为Active. 
通过ZooKeeper实现自动的故障切换

系统逻辑结构">
<meta property="og:image" content="http://7xokux.com1.z0.glb.clouddn.com/hdfs_qjm_architecture.png">
<meta property="og:updated_time" content="2016-04-13T11:56:25.850Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="HDFS HA Deployment (With QJM)">
<meta name="twitter:description" content="运营管理平台HDFS高可用配置-实施版Overview目的以及方案目的为解决当前平台中NameNode为单点的问题. 方案如下: 

通过QJM在集群中实现两个NameNode, 一个为Active, 一个Standby.Standby为Active的热备份. 则Active节点产生故障, 可以手动故障切换Standby为Active. 
通过ZooKeeper实现自动的故障切换

系统逻辑结构">
<meta name="twitter:image" content="http://7xokux.com1.z0.glb.clouddn.com/hdfs_qjm_architecture.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-HDFS高可用部署" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/04/13/HDFS高可用部署/" class="article-date">
  <time datetime="2016-04-13T14:21:25.000Z" itemprop="datePublished">2016-04-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      HDFS HA Deployment (With QJM)
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="运营管理平台HDFS高可用配置-实施版"><a href="#运营管理平台HDFS高可用配置-实施版" class="headerlink" title="运营管理平台HDFS高可用配置-实施版"></a>运营管理平台HDFS高可用配置-实施版</h1><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><h3 id="目的以及方案"><a href="#目的以及方案" class="headerlink" title="目的以及方案"></a>目的以及方案</h3><p>目的为解决当前平台中NameNode为单点的问题. 方案如下: </p>
<ol>
<li>通过QJM在集群中实现两个NameNode, 一个为Active, 一个Standby.Standby为Active的热备份. 则Active节点产生故障, 可以手动故障切换Standby为Active. </li>
<li>通过ZooKeeper实现自动的故障切换</li>
</ol>
<h3 id="系统逻辑结构"><a href="#系统逻辑结构" class="headerlink" title="系统逻辑结构"></a>系统逻辑结构</h3><p><img src="http://7xokux.com1.z0.glb.clouddn.com/hdfs_qjm_architecture.png" alt=""></p>
<h3 id="实际部署情况"><a href="#实际部署情况" class="headerlink" title="实际部署情况"></a>实际部署情况</h3><p>在原来系统的基础上, 添加一个NameNode进程, 每个NameNode伴随一个DFSZKFailover. 另外需要三个JournalNode. 以及构建ZooKeeper, 三个QuorumPeerMain进程.  </p>
<ul>
<li>master:  NameNode, QuorumPeerMain, JournalNode, DFSZKFailover-<br>Controller, DataNode</li>
<li>slave1: NameNode, QuorumPeerMain, JournalNode, DFSZKFailover-<br>Controller, DataNode</li>
<li>slave2: QuorumPeerMain, JournalNode, DataNode</li>
</ul>
<p>配置前请关闭所有HDFS相关进程. </p>
<h2 id="配置热备份"><a href="#配置热备份" class="headerlink" title="配置热备份"></a>配置热备份</h2><h3 id="1-SSH配置"><a href="#1-SSH配置" class="headerlink" title="1. SSH配置"></a>1. SSH配置</h3><p>由于slave1也充当NameNode的角色, 并且两个NameNode之间也需要免密通信, 故需要<br>配置slave1到另外两台机器的SHH免密通信. 具体过程略. 过程中如出现 “.. to open”, 可以将id_rsa权限修改为600即可. </p>
<pre><code>chmod 600 id_rsa
</code></pre><h3 id="2-创建journal-edits文件夹"><a href="#2-创建journal-edits文件夹" class="headerlink" title="2.创建journal_edits文件夹"></a>2.创建journal_edits文件夹</h3><p>三台机器分别执行以下命令</p>
<pre><code>su Hadoop 
cd ~
mkdir jounal_edits    
</code></pre><h3 id="3-修改hdfs-site-xml"><a href="#3-修改hdfs-site-xml" class="headerlink" title="3.修改hdfs-site.xml"></a>3.修改hdfs-site.xml</h3><p>修改三台机器的hdfs-site.xml.<br>在测试环境中, 用户名为 “Hadoop”, 三台机器域名以及IP分别为: </p>
<pre><code>- master: 172.16.41.24
- slave1: 172.16.41.25
- slave2: 172.16.41.26
</code></pre><p>在不同环境中, 相关的配置要修改. </p>
<pre><code>&lt;property&gt;
    &lt;name&gt;dfs.replication&lt;/name&gt;
    &lt;value&gt;3&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
    &lt;value&gt;file:/home/Hadoop/name&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
    &lt;value&gt;file:/home/Hadoop/data&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;dfs.nameservices&lt;/name&gt;
    &lt;value&gt;cloudhdfs&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;dfs.ha.namenodes.cloudhdfs&lt;/name&gt;
    &lt;value&gt;name1,name2&lt;/value&gt;
&lt;/property&gt; 
&lt;property&gt;
    &lt;name&gt;dfs.namenode.rpc-address.cloudhdfs.name1&lt;/name&gt;
    &lt;value&gt;172.16.41.24:8020&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;dfs.namenode.rpc-address.cloudhdfs.name2&lt;/name&gt;
    &lt;value&gt;172.16.41.25:8020&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;dfs.namenode.http-address.cloudhdfs.name1&lt;/name&gt;
    &lt;value&gt;172.16.41.24:50070&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;dfs.namenode.http-address.cloudhdfs.name2&lt;/name&gt;
    &lt;value&gt;172.16.41.25:50070&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;
    &lt;value&gt;qjournal://master:8485;slave1:8485;slave2:8485/cloudhdfs&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;dfs.journalnode.edit.dir&lt;/name&gt;
    &lt;value&gt;/home/Hadoop/journal_edits&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
       &lt;name&gt;dfs.client.failover.proxy.provider.cloudhdfs&lt;/name&gt;
      &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvide&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;
    &lt;value&gt;sshfence&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;
    &lt;value&gt;/home/Hadoop/.ssh/id_rsa&lt;/value&gt;
&lt;/property&gt;
</code></pre><h3 id="4-修改core-site-xml"><a href="#4-修改core-site-xml" class="headerlink" title="4.修改core-site.xml"></a>4.修改core-site.xml</h3><p>三台机器都修改. </p>
<pre><code>&lt;property&gt;
    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
    &lt;value&gt;/home/Hadoop/tmp&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;fs.defaultFS&lt;/name&gt;
    &lt;value&gt;hdfs://cloudhdfs&lt;/value&gt;
&lt;/property&gt;
</code></pre><h3 id="5-开启JournalNode"><a href="#5-开启JournalNode" class="headerlink" title="5.开启JournalNode"></a>5.开启JournalNode</h3><pre><code>hadoop-daemon.sh start journalnode
</code></pre><p>开启后通过<code>jps</code>查看是否有JournalNode进程. </p>
<h3 id="6-初始化SharedEdits"><a href="#6-初始化SharedEdits" class="headerlink" title="6.初始化SharedEdits"></a>6.初始化SharedEdits</h3><p>在master执行:</p>
<pre><code>hdfs namenode -initializeSharedEdits
</code></pre><h3 id="7-启动NameNode1"><a href="#7-启动NameNode1" class="headerlink" title="7.启动NameNode1"></a>7.启动NameNode1</h3><p>在master执行: </p>
<pre><code>hadoop-daemon.sh start namenode
</code></pre><p>通过<code>jps</code>查看是否启动成功</p>
<h3 id="8-将fsimage从NameNode1同步到NameNode2"><a href="#8-将fsimage从NameNode1同步到NameNode2" class="headerlink" title="8.将fsimage从NameNode1同步到NameNode2"></a>8.将fsimage从NameNode1同步到NameNode2</h3><p>在slave1执行</p>
<pre><code>hdfs namenode -bootstrapStandby 
</code></pre><h3 id="9-启动NameNode2-以及DataNodes"><a href="#9-启动NameNode2-以及DataNodes" class="headerlink" title="9.启动NameNode2, 以及DataNodes"></a>9.启动NameNode2, 以及DataNodes</h3><p>在slave1执行</p>
<pre><code>hadoop-daemon.sh start namenode
</code></pre><p>在所有机器执行: </p>
<pre><code>hadoop-daemon.sh start datanode
</code></pre><p><strong>验证</strong>:</p>
<p>访问两个NameNodeUI, 测试环境中分别为: </p>
<ul>
<li><a href="http://172.16.41.24:50070" target="_blank" rel="external">http://172.16.41.24:50070</a></li>
<li><a href="http://172.16.41.25:50070" target="_blank" rel="external">http://172.16.41.25:50070</a></li>
</ul>
<p>可以看到两个NameNode的状态都为Standby. 执行以下命令进行一次failover: </p>
<pre><code>hdfs haadmin name2 name1 
</code></pre><p>刷新UI页面, 可以看到一个为Active, 一个为Standby. 新建测试文件夹: </p>
<pre><code>hdfs dfs -mkdir /ha_test
</code></pre><p>切换NameNode: </p>
<pre><code>hdfs haadmin name1 name2
</code></pre><p>查看刚刚新建的文件夹是否存在:</p>
<pre><code>hdfs dfs -ls /
</code></pre><p>如果出现刚刚创建的/ha_test即为成功. </p>
<h2 id="配置ZooKeeper自动切换"><a href="#配置ZooKeeper自动切换" class="headerlink" title="配置ZooKeeper自动切换"></a>配置ZooKeeper自动切换</h2><p>首先将所有HDFS相关进程关闭. </p>
<h3 id="1-配置ZooKeeper"><a href="#1-配置ZooKeeper" class="headerlink" title="1. 配置ZooKeeper"></a>1. 配置ZooKeeper</h3><p>在三台机器新建文件夹: </p>
<pre><code>cd ~
mkdir zookeeper
cd zookeeper
</code></pre><p>三台机器分别进入zookeeper, 新建myid, 分别输入1,2,3.</p>
<pre><code>vi myid
</code></pre><p>将zookeeper-3.4.6.tar.gz拷贝到三台机器的/home/Hadoop/下, 解压. </p>
<pre><code>cd ~
tar -zxvf zookeeper-3.4.6.tar.gz
</code></pre><p>进入zookeeper的conf目录</p>
<pre><code>cd ~/zookeeper-3.4.6/conf
</code></pre><p>新建zoo.cfg, 将以下配置复制到其中. </p>
<pre><code>tickTime=2000
initLimit=10
syncLimit=5
dataDir=/home/Hadoop/zookeeper
clientPort=2181
server.1=master:2888:3888
server.2=slave1:2888:3888
server.3=slave2:2888:3888
</code></pre><h3 id="2-配置hdfs-site-xml-启动自动切换"><a href="#2-配置hdfs-site-xml-启动自动切换" class="headerlink" title="2.配置hdfs-site.xml, 启动自动切换"></a>2.配置hdfs-site.xml, 启动自动切换</h3><p>在三台机器的hdfs-site.xml添加以下内容:</p>
<pre><code>&lt;property&gt;
    &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
</code></pre><h3 id="3-配置core-site-xml-指定zookeeper"><a href="#3-配置core-site-xml-指定zookeeper" class="headerlink" title="3.配置core-site.xml, 指定zookeeper"></a>3.配置core-site.xml, 指定zookeeper</h3><p>在三台机器的core-site.xml中添加以下内容</p>
<pre><code>&lt;property&gt;
    &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;
    &lt;value&gt;master:2181,slave1:2181,slave2:2181&lt;/value&gt;
&lt;/property&gt;
</code></pre><h3 id="4-启动并初始化ZooKeeper"><a href="#4-启动并初始化ZooKeeper" class="headerlink" title="4. 启动并初始化ZooKeeper"></a>4. 启动并初始化ZooKeeper</h3><p>开启ZooKeeper, 在三台机器分别执行: </p>
<pre><code>cd ~/zookeeper-3.4.6/bin
zkServer.sh start
</code></pre><p>启动后<code>jps</code>, 应有进程QuorumPeerMain.</p>
<p>在master上执行以下命令</p>
<pre><code>hdfs zkfc -formatZK
</code></pre><h3 id="5-启动所有JournalNode-NameNode-Datanode"><a href="#5-启动所有JournalNode-NameNode-Datanode" class="headerlink" title="5. 启动所有JournalNode, NameNode, Datanode"></a>5. 启动所有JournalNode, NameNode, Datanode</h3><p>master: </p>
<pre><code>hadoop-daemon.sh start journalnode
hadoop-daemon.sh start namenode
hadoop-daemon.sh start datanode
</code></pre><p>slave1:</p>
<pre><code>hadoop-daemon.sh start journalnode
hadoop-daemon.sh start namenode
hadoop-daemon.sh start datanode
</code></pre><p>slave2: </p>
<pre><code>hadoop-daemon.sh start journalnode
hadoop-daemon.sh start datanode
</code></pre><h3 id="6-启动ZKFC"><a href="#6-启动ZKFC" class="headerlink" title="6. 启动ZKFC"></a>6. 启动ZKFC</h3><p>在master和slave1上分别执行: </p>
<pre><code>hadoop-daemon.sh start zkfc
</code></pre><p>执行<code>jps</code>之后, 出现DFSZKFailoverController进程. </p>
<h3 id="7-验证"><a href="#7-验证" class="headerlink" title="7. 验证"></a>7. 验证</h3><p>通过UI查看为Active的NameNode, 比如为master上的NameNode.<br>kill掉相关进程: </p>
<pre><code>kill xxxx 
</code></pre><p>转到之前为Standby的NameNode UI, 此处为slave1. 状态变为Active, 则为自动切换成功. </p>
<p><strong>在以后启动HDFS的过程中, 不需要每个进程单独启动. 依然可以使用<code>start-dfs.sh</code></strong></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/04/13/HDFS高可用部署/" data-id="cimysxx0a00008smxp8svf2fh" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HDFS/">HDFS</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2016/04/13/hello-world/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Hello World</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/HDFS/">HDFS</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/HDFS/" style="font-size: 10px;">HDFS</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/04/13/HDFS高可用部署/">HDFS HA Deployment (With QJM)</a>
          </li>
        
          <li>
            <a href="/2016/04/13/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>